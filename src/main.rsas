use std::os::unix::io::AsRawFd;
use tokio::net::{TcpListener, TcpStream};
use tokio::io;
use std::sync::Arc;
use std::sync::atomic::{AtomicU64, AtomicBool, Ordering};
use std::time::Duration;
use std::net::SocketAddr;

// Cache-aligned stats to prevent false sharing
#[repr(align(64))]
struct Stats {
    bytes: AtomicU64,
    conns: AtomicU64,
    errors: AtomicU64,
    rejected: AtomicU64,
}

impl Stats {
    fn new() -> Self {
        Self {
            bytes: AtomicU64::new(0),
            conns: AtomicU64::new(0),
            errors: AtomicU64::new(0),
            rejected: AtomicU64::new(0),
        }
    }
}

struct Config {
    listen_addr: String,
    upstream_addr: String,
    max_connections: u64,
    num_workers: usize,
}

#[tokio::main(flavor = "multi_thread")]
async fn main() -> io::Result<()> {
    // Parse config with proper lifetime management
    let config = parse_config().await?;

    let stats = Arc::new(Stats::new());
    let shutdown = Arc::new(AtomicBool::new(false));

    // Stats reporter
    tokio::spawn(report_stats(Arc::clone(&stats), Arc::clone(&shutdown)));

    // Graceful shutdown handler
    tokio::spawn(shutdown_handler(Arc::clone(&shutdown)));

    // Spawn listener per CPU with SO_REUSEPORT for kernel load balancing
    let mut handles = vec![];
    for cpu_id in 0..config.num_workers {
        let upstream = config.upstream_addr.clone();
        let listen = config.listen_addr.clone();
        let stats = Arc::clone(&stats);
        let shutdown = Arc::clone(&shutdown);
        let max_conns = config.max_connections;

        let handle = tokio::spawn(async move {
            if let Err(e) = run_listener(&listen, &upstream, cpu_id, stats, shutdown, max_conns).await {
                eprintln!("Worker {} error: {}", cpu_id, e);
            }
        });
        handles.push(handle);
    }

    // Wait for all listeners
    futures::future::join_all(handles).await;
    println!("âœ… Shutdown complete");
    Ok(())
}

async fn parse_config() -> io::Result<Config> {
    let args: Vec<String> = std::env::args().collect();

    // Clone strings to avoid lifetime issues
    let listen_addr = args.get(1)
    .map(|s| s.to_string())
    .unwrap_or_else(|| "0.0.0.0:8080".to_string());

    let upstream_addr = args.get(2)
    .map(|s| s.to_string())
    .unwrap_or_else(|| "127.0.0.1:80".to_string());

    let max_connections = args.get(3)
    .and_then(|s| s.parse().ok())
    .unwrap_or(100000);

    let num_workers = std::thread::available_parallelism()
    .map(|n| n.get())
    .unwrap_or(4);

    // Test upstream connectivity
    println!("ğŸ” Testing upstream {}...", upstream_addr);
    match tokio::time::timeout(
        Duration::from_secs(3),
                               TcpStream::connect(&upstream_addr)
    ).await {
        Ok(Ok(_)) => println!("âœ… Upstream reachable"),
        Ok(Err(e)) => {
            eprintln!("âŒ Cannot connect to upstream: {}", e);
            eprintln!("ğŸ’¡ Usage: {} <listen_addr> <upstream_addr> [max_connections]", args[0]);
            eprintln!("   Example: {} 0.0.0.0:8080 127.0.0.1:80 100000", args[0]);
            return Err(e);
        }
        Err(_) => {
            return Err(io::Error::new(
                io::ErrorKind::TimedOut,
                "upstream timeout"
            ));
        }
    }

    println!();
    println!("ğŸš€ ULTRA-FAST ZERO-COPY TCP PROXY");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“¡ Listen:      {}", listen_addr);
    println!("ğŸ¯ Upstream:    {}", upstream_addr);
    println!("ğŸ§µ Workers:     {} (CPU-pinned)", num_workers);
    println!("ğŸ”’ Max conns:   {}", max_connections);
    println!("âš¡ Features:    Zero-copy, SO_REUSEPORT, TCP_NODELAY");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!();

    Ok(Config {
        listen_addr,
       upstream_addr,
       max_connections,
       num_workers,
    })
}

async fn run_listener(
    listen_addr: &str,
    upstream: &str,
    cpu_id: usize,
    stats: Arc<Stats>,
    shutdown: Arc<AtomicBool>,
    max_connections: u64,
) -> io::Result<()> {
    // Pin this task to specific CPU
    #[cfg(target_os = "linux")]
    pin_to_cpu(cpu_id);

    // Create optimized listener with SO_REUSEPORT
    let listener = create_listener(listen_addr).await?;

    println!("âœ… Worker {} ready on CPU {}", cpu_id, cpu_id);

    loop {
        // Check shutdown signal
        if shutdown.load(Ordering::Relaxed) {
            println!("Worker {} shutting down...", cpu_id);
            break;
        }

        // Check connection limit
        let current_conns = stats.conns.load(Ordering::Relaxed);
        if current_conns >= max_connections {
            stats.rejected.fetch_add(1, Ordering::Relaxed);
            tokio::time::sleep(Duration::from_millis(10)).await;
            continue;
        }

        match listener.accept().await {
            Ok((client, peer_addr)) => {
                let upstream = upstream.to_string();
                let stats = Arc::clone(&stats);

                stats.conns.fetch_add(1, Ordering::Relaxed);

                // Spawn connection handler
                tokio::spawn(async move {
                    match handle_connection(client, &upstream, peer_addr).await {
                        Ok(bytes) => {
                            stats.bytes.fetch_add(bytes, Ordering::Relaxed);
                        }
                        Err(_) => {
                            stats.errors.fetch_add(1, Ordering::Relaxed);
                        }
                    }
                    stats.conns.fetch_sub(1, Ordering::Relaxed);
                });
            }
            Err(_) => {
                stats.errors.fetch_add(1, Ordering::Relaxed);
            }
        }
    }

    Ok(())
}

async fn create_listener(addr: &str) -> io::Result<TcpListener> {
    use std::net::SocketAddr;

    // Parse the address
    let socket_addr: SocketAddr = addr.parse()
    .map_err(|e| io::Error::new(io::ErrorKind::InvalidInput, e))?;

    // Create socket with SO_REUSEPORT BEFORE binding
    let socket = socket2::Socket::new(
        if socket_addr.is_ipv4() { socket2::Domain::IPV4 } else { socket2::Domain::IPV6 },
            socket2::Type::STREAM,
            Some(socket2::Protocol::TCP),
    )?;

    // Set SO_REUSEPORT before binding
    socket.set_reuse_port(true)?;
    socket.set_reuse_address(true)?;
    socket.set_nonblocking(true)?;

    // Bind
    socket.bind(&socket_addr.into())?;
    socket.listen(4096)?;

    // Convert to tokio TcpListener
    let std_listener: std::net::TcpListener = socket.into();
    std_listener.set_nonblocking(true)?;
    let listener = TcpListener::from_std(std_listener)?;

    let fd = listener.as_raw_fd();

    unsafe {
        // TCP_FASTOPEN
        let backlog: libc::c_int = 4096;
        libc::setsockopt(
            fd, libc::IPPROTO_TCP, libc::TCP_FASTOPEN,
            &backlog as *const _ as *const libc::c_void,
            std::mem::size_of_val(&backlog) as libc::socklen_t
        );

        // Optimal buffers - 64KB for high throughput
        let bufsize: libc::c_int = 64 * 1024;
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_RCVBUF,
            &bufsize as *const _ as *const libc::c_void,
            std::mem::size_of_val(&bufsize) as libc::socklen_t
        );
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_SNDBUF,
            &bufsize as *const _ as *const libc::c_void,
            std::mem::size_of_val(&bufsize) as libc::socklen_t
        );

        // TCP_DEFER_ACCEPT - only accept when data ready
        let timeout: libc::c_int = 1;
        libc::setsockopt(
            fd, libc::IPPROTO_TCP, libc::TCP_DEFER_ACCEPT,
            &timeout as *const _ as *const libc::c_void,
            std::mem::size_of_val(&timeout) as libc::socklen_t
        );
    }

    Ok(listener)
}

async fn handle_connection(
    mut client: TcpStream,
    upstream_addr: &str,
    _peer: SocketAddr,
) -> io::Result<u64> {
    // Fast cleanup on close
    client.set_linger(Some(Duration::from_secs(0)))?;

    // Connect with timeout
    let mut upstream = match tokio::time::timeout(
        Duration::from_secs(5),
                                                  TcpStream::connect(upstream_addr)
    ).await {
        Ok(Ok(stream)) => stream,
        Ok(Err(e)) => return Err(e),
        Err(_) => {
            return Err(io::Error::new(
                io::ErrorKind::TimedOut,
                "upstream timeout"
            ));
        }
    };

    // Optimize both sockets
    optimize_socket(&client)?;
    optimize_socket(&upstream)?;

    // Zero-copy bidirectional transfer
    // Uses splice() on Linux for kernel-space data transfer
    let (tx, rx) = io::copy_bidirectional(&mut client, &mut upstream).await?;

    Ok(tx + rx)
}

#[inline(always)]
fn optimize_socket(stream: &TcpStream) -> io::Result<()> {
    let fd = stream.as_raw_fd();

    unsafe {
        let one: libc::c_int = 1;

        // TCP_NODELAY - disable Nagle for low latency
        libc::setsockopt(
            fd, libc::IPPROTO_TCP, libc::TCP_NODELAY,
            &one as *const _ as *const libc::c_void,
            std::mem::size_of_val(&one) as libc::socklen_t
        );

        // TCP_QUICKACK - send ACKs immediately
        #[cfg(target_os = "linux")]
        libc::setsockopt(
            fd, libc::IPPROTO_TCP, libc::TCP_QUICKACK,
            &one as *const _ as *const libc::c_void,
            std::mem::size_of_val(&one) as libc::socklen_t
        );

        // Optimal buffers - 64KB
        let bufsize: libc::c_int = 64 * 1024;
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_RCVBUF,
            &bufsize as *const _ as *const libc::c_void,
            std::mem::size_of_val(&bufsize) as libc::socklen_t
        );
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_SNDBUF,
            &bufsize as *const _ as *const libc::c_void,
            std::mem::size_of_val(&bufsize) as libc::socklen_t
        );

        // SO_KEEPALIVE for health checks
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_KEEPALIVE,
            &one as *const _ as *const libc::c_void,
            std::mem::size_of_val(&one) as libc::socklen_t
        );

        // SO_LINGER(0) for instant close
        let linger = libc::linger {
            l_onoff: 1,
            l_linger: 0,
        };
        libc::setsockopt(
            fd, libc::SOL_SOCKET, libc::SO_LINGER,
            &linger as *const _ as *const libc::c_void,
            std::mem::size_of::<libc::linger>() as libc::socklen_t
        );
    }

    Ok(())
}

async fn report_stats(stats: Arc<Stats>, shutdown: Arc<AtomicBool>) {
    let mut interval = tokio::time::interval(Duration::from_secs(1));
    let mut last_bytes = 0u64;

    loop {
        interval.tick().await;

        if shutdown.load(Ordering::Relaxed) {
            break;
        }

        let bytes = stats.bytes.load(Ordering::Relaxed);
        let conns = stats.conns.load(Ordering::Relaxed);
        let errors = stats.errors.load(Ordering::Relaxed);
        let rejected = stats.rejected.load(Ordering::Relaxed);

        let bytes_diff = bytes.saturating_sub(last_bytes);
        last_bytes = bytes;

        let gbps = (bytes_diff * 8) as f64 / 1_000_000_000.0;
        let total_gb = bytes as f64 / 1_000_000_000.0;

        println!(
            "âš¡ {:6} active | {:6} err | {:6} rej | {:7.2} Gbps | {:9.2} GB total",
            conns, errors, rejected, gbps, total_gb
        );
    }
}

async fn shutdown_handler(shutdown: Arc<AtomicBool>) {
    tokio::signal::ctrl_c().await.ok();
    println!("\nğŸ›‘ Shutting down gracefully...");
    shutdown.store(true, Ordering::Relaxed);

    // Give connections time to drain
    tokio::time::sleep(Duration::from_secs(2)).await;
}

#[inline(always)]
#[cfg(target_os = "linux")]
fn pin_to_cpu(cpu_id: usize) {
    unsafe {
        let mut set: libc::cpu_set_t = std::mem::zeroed();
        libc::CPU_SET(cpu_id, &mut set);
        libc::sched_setaffinity(0, std::mem::size_of::<libc::cpu_set_t>(), &set);
    }
}

#[cfg(not(target_os = "linux"))]
fn pin_to_cpu(_cpu_id: usize) {
    // No-op on non-Linux
}
